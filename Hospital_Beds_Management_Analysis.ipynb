{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8RWszrVkC/Hl5XRd4fs8Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anubis-1001/Colab-notebooks/blob/main/Hospital_Beds_Management_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "K0nPEN4yLlWk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9COntLe13vGn",
        "outputId": "8031802d-8c51-4262-8fb6-eb95879e94cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'hospital-beds-management' dataset.\n",
            "Path to dataset files: /kaggle/input/hospital-beds-management\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"jaderz/hospital-beds-management\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patients = pd.read_csv(f'{path}/patients.csv')\n",
        "services_weekly = pd.read_csv(f'{path}/services_weekly.csv')\n",
        "staff = pd.read_csv(f'{path}/staff.csv')\n",
        "staff_schedule = pd.read_csv(f'{path}/staff_schedule.csv')"
      ],
      "metadata": {
        "id": "yYMQOhir41T-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_week_of_year(dt):\n",
        "    return dt.isocalendar().week\n",
        "\n",
        "def get_week_data(patient, feature):\n",
        "    wa = patient['week_arrival']\n",
        "    srv = patient['service']\n",
        "    match = services_weekly[\n",
        "        (services_weekly['week'] == wa) &\n",
        "        (services_weekly['service'] == srv)\n",
        "    ][feature]\n",
        "    return match.iloc[0] if not match.empty else None\n",
        "\n",
        "patients['dt_arrival'] = pd.to_datetime(patients['arrival_date'])\n",
        "patients['dt_departure'] = pd.to_datetime(patients['departure_date'])\n",
        "patients['week_arrival'] = patients['dt_arrival'].apply(get_week_of_year)\n",
        "patients['week_departure'] = patients['dt_departure'].apply(get_week_of_year)\n",
        "\n",
        "weekly_services_attr = ['staff_morale', 'patient_satisfaction', 'event']\n",
        "\n",
        "for feature in weekly_services_attr:\n",
        "  patients[f'pat_{feature}'] = patients.apply(lambda pat: get_week_data(pat, feature), axis=1)\n",
        "\n",
        "\n",
        "patients['stay_duration'] = ( pd.to_datetime(patients['departure_date'], format=\"%Y-%m-%d\") - pd.to_datetime(patients['arrival_date'], format=\"%Y-%m-%d\" ) ).dt.days\n",
        "\n",
        "patients['has_ICU'] = patients['service'] == 'ICU'\n",
        "\n",
        "ohe = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "patients_encoded = ohe.fit_transform(patients[['pat_event']])\n",
        "\n",
        "pat_encoded_df = pd.DataFrame(patients_encoded, columns=ohe.get_feature_names_out(), index=patients.index)\n",
        "\n",
        "patients = pd.concat([patients, pat_encoded_df], axis=1)"
      ],
      "metadata": {
        "id": "eDgyEc2Ov00c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = patients.drop(columns=['satisfaction', 'patient_id', 'name', 'arrival_date', 'departure_date', 'service', 'dt_departure', 'dt_arrival', 'pat_event'])\n",
        "X = patients.drop(columns=['satisfaction', 'patient_id', 'name', 'arrival_date', 'departure_date', 'service', 'dt_departure', 'dt_arrival', 'pat_event', 'week_arrival', 'week_departure'])\n",
        "# X = patients[[ 'age', 'stay_duration', 'has_ICU', 'pat_event_donation' ]]\n",
        "y = patients['satisfaction']\n",
        "y_strata = pd.qcut(y, q=4, labels=False)\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "X_train, X_test, y_train,  y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y_strata)\n",
        "X_train = std_scaler.fit_transform(X_train)\n",
        "X_test = std_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "N0cDDSoGVXuB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "linear_reg.fit(X, y)\n",
        "y_pred = linear_reg.predict(X_test)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mean_absolute_error = mean_absolute_error(y_test, y_pred)\n",
        "mean_squared_error = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"r2: {r2:.2f}\")\n",
        "print(f\"mean_absolute_error: {mean_absolute_error:.2f}\")\n",
        "print(f\"mean_squared_error: {mean_squared_error:.2f}\")"
      ],
      "metadata": {
        "id": "Ho3QGdSze4uR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a61457a-7ae0-4ab3-e60f-5a1791ba15d8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2: -0.03\n",
            "mean_absolute_error: 9.62\n",
            "mean_squared_error: 131.32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "ridge = Ridge()\n",
        "\n",
        "param_grid = {\n",
        "    'alpha': [ 0.01, 0.1, 1, 10, 100  ],\n",
        "    'solver': ['auto', 'svd', 'cholesky'],\n",
        "     'fit_intercept': [True, False]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "      estimator=ridge,\n",
        "      param_grid=param_grid,\n",
        "      scoring='neg_mean_squared_error',\n",
        "      cv=5,\n",
        "      n_jobs=-1,\n",
        "      verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Ridge\")\n",
        "print(\"=\"*50)\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n",
        "print(\"MAE\")\n",
        "pred = grid_search.best_estimator_.predict(X_test)\n",
        "\n",
        "print(mean_)\n",
        "\n",
        "\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'criterion': ['squared_error', 'friedman_mse', 'absolute_error'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 3, 5, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "      estimator=dt,\n",
        "      param_grid=param_grid,\n",
        "      scoring='neg_mean_squared_error',\n",
        "      cv=5,\n",
        "      n_jobs=-1,\n",
        "      verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"DT\")\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n",
        "print(\"Feature importances\")\n",
        "print(std_scaler.feature_names_in_)\n",
        "print(grid_search.best_estimator_.feature_importances_)\n",
        "\n",
        "lasso = Lasso()\n",
        "\n",
        "param_grid = {\n",
        "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
        "    'fit_intercept': [True, False],\n",
        "    'max_iter': [1000, 5000, 10000]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "      estimator=lasso,\n",
        "      param_grid=param_grid,\n",
        "      scoring='neg_mean_squared_error',\n",
        "      cv=5,\n",
        "      n_jobs=-1,\n",
        "      verbose=1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Lasso\")\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)"
      ],
      "metadata": {
        "id": "wYOgC0HRU9vr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "232eb736-445c-4b56-b8c0-ce98f1a53eb8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "Ridge\n",
            "==================================================\n",
            "{'alpha': 100, 'fit_intercept': True, 'solver': 'auto'}\n",
            "-135.7440560638974\n",
            "MAE\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mean_' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-652254091.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mean_' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "best_dt = grid_search.best_estimator_\n",
        "pred = best_dt.predict(X_test)\n",
        "\n",
        "mean_error = mean_absolute_error(y_test, pred)\n",
        "\n",
        "print(f\"mean absolute error: {mean_error}\")"
      ],
      "metadata": {
        "id": "7l8LO7bDPyEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"max_depth\": [None, 10, 20, 30],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    \"bootstrap\": [True, False]\n",
        "}\n",
        "\n",
        "gs_rf = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "gs_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best params:\", gs_rf.best_params_)\n",
        "print(\"Best score:\", gs_rf.best_score_)\n",
        "\n",
        "rf_pred=gs_rf.best_estimator_.predict(X_test)\n",
        "score=mean_absolute_error(y_test, rf_pred)\n",
        "\n",
        "print(f\"Mean Score Value {score}\")"
      ],
      "metadata": {
        "id": "idgIuGJzUdL-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}